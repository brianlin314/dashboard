{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef9461e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 11:15:53.844156: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-11 11:15:54.013328: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-11 11:15:54.474426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ne6101157/anaconda3/env/trackformer/lib\n",
      "2022-11-11 11:15:54.474548: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ne6101157/anaconda3/env/trackformer/lib\n",
      "2022-11-11 11:15:54.474554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# import libraries \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, re, time, math, tqdm, itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #資料視覺化\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b74c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(Input_csv, label):\n",
    "    df=pd.read_csv(Input_csv, index_col=None, low_memory=False)\n",
    "\n",
    "    print(Input_csv,\"資料總數: \",df.shape) #檢查數據的大小 \n",
    "    df['Label'].value_counts()\n",
    "    df=df[df['Label'].isin([label])]\n",
    "    print(label,\"選擇資料總數: \",df.shape)\n",
    "    df['Label'].value_counts()\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    df_list.append(df)\n",
    "    return \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5256e05f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./CIC-IDS2018/02-22-2018.csv 資料總數:  (1048575, 80)\n",
      "Benign 選擇資料總數:  (1048213, 80)\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "./CIC-IDS2018/02-14-2018.csv 資料總數:  (1048575, 80)\n",
      "Benign 選擇資料總數:  (667626, 80)\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "./CIC-IDS2018/02-15-2018.csv 資料總數:  (1048575, 80)\n",
      "DoS attacks-GoldenEye 選擇資料總數:  (41508, 80)\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "./CIC-IDS2018/02-16-2018.csv 資料總數:  (1048575, 80)\n",
      "DoS attacks-SlowHTTPTest 選擇資料總數:  (139890, 80)\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "./CIC-IDS2018/02-15-2018.csv 資料總數:  (1048575, 80)\n",
      "DoS attacks-Slowloris 選擇資料總數:  (10990, 80)\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "./CIC-IDS2018/02-14-2018.csv 資料總數:  (1048575, 80)\n",
      "FTP-BruteForce 選擇資料總數:  (193360, 80)\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "./CIC-IDS2018/02-20-2018.csv 資料總數:  (7948748, 84)\n",
      "DDoS attacks-LOIC-HTTP 選擇資料總數:  (576191, 84)\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "./CIC-IDS2018/03-02-2018.csv 資料總數:  (1048575, 80)\n",
      "Bot 選擇資料總數:  (286191, 80)\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "df_list=[]\n",
    "load_data('./CIC-IDS2018/02-22-2018.csv', 'Benign') #Benign 1048213\n",
    "load_data('./CIC-IDS2018/02-14-2018.csv', 'Benign') #Benign 667626\n",
    "load_data('./CIC-IDS2018/02-15-2018.csv', 'DoS attacks-GoldenEye') #DoS attacks-Gloden Eye 41508\n",
    "load_data('./CIC-IDS2018/02-16-2018.csv', 'DoS attacks-SlowHTTPTest') #DoS attacks-SlowHTTPTest 139890\n",
    "load_data('./CIC-IDS2018/02-15-2018.csv', 'DoS attacks-Slowloris') #DoS attacks-Slowloris 10990\n",
    "load_data('./CIC-IDS2018/02-14-2018.csv', 'FTP-BruteForce') #FTP-Brute Force 193360\n",
    "load_data('./CIC-IDS2018/02-20-2018.csv', 'DDoS attacks-LOIC-HTTP') #DDoS attacks-LOIC-HTTP 576191\n",
    "load_data('./CIC-IDS2018/03-02-2018.csv', 'Bot') #Bot 286191\n",
    "df = pd.concat(df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "140d4a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows 個數(Sample): 2963969\n",
      "Columns 個數(Feature): 84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Benign                      1715839\n",
       "DDoS attacks-LOIC-HTTP       576191\n",
       "Bot                          286191\n",
       "FTP-BruteForce               193360\n",
       "DoS attacks-SlowHTTPTest     139890\n",
       "DoS attacks-GoldenEye         41508\n",
       "DoS attacks-Slowloris         10990\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #檢查數據的大小 \n",
    "print('Rows 個數(Sample): %d' %  df.shape[0])\n",
    "print('Columns 個數(Feature): %d' %  df.shape[1])\n",
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcbbc2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總共的Columns數: 84\n"
     ]
    }
   ],
   "source": [
    "print('總共的Columns數: %d' % len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b23848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns #檢查資料的columns有哪些\n",
    "df = df.drop(['Flow ID', 'Src IP', 'Src Port', 'Dst IP'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb1abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chage_dtype={'Dst Port': 'int', 'Protocol': 'int', 'Timestamp': 'object', 'Flow Duration': 'int', 'Tot Fwd Pkts': 'int', 'Tot Bwd Pkts': 'int', 'TotLen Fwd Pkts': 'int', 'TotLen Bwd Pkts': 'int', 'Fwd Pkt Len Max': 'int', 'Fwd Pkt Len Min': 'int', 'Fwd Pkt Len Mean': 'float', 'Fwd Pkt Len Std': 'float', 'Bwd Pkt Len Max': 'int', 'Bwd Pkt Len Min': 'int', 'Bwd Pkt Len Mean': 'float', 'Bwd Pkt Len Std': 'float', 'Flow Byts/s': 'float', 'Flow Pkts/s': 'float', 'Flow IAT Mean': 'float', 'Flow IAT Std': 'float', 'Flow IAT Max': 'int', 'Flow IAT Min': 'int', 'Fwd IAT Tot': 'int', 'Fwd IAT Mean': 'float', 'Fwd IAT Std': 'float', 'Fwd IAT Max': 'int', 'Fwd IAT Min': 'int', 'Bwd IAT Tot': 'int', 'Bwd IAT Mean': 'float', 'Bwd IAT Std': 'float', 'Bwd IAT Max': 'int', 'Bwd IAT Min': 'int', 'Fwd PSH Flags': 'int', 'Bwd PSH Flags': 'int', 'Fwd URG Flags': 'int', 'Bwd URG Flags': 'int', 'Fwd Header Len': 'int', 'Bwd Header Len': 'int', 'Fwd Pkts/s': 'float', 'Bwd Pkts/s': 'float', 'Pkt Len Min': 'int', 'Pkt Len Max': 'int', 'Pkt Len Mean': 'float', 'Pkt Len Std': 'float', 'Pkt Len Var': 'float', 'FIN Flag Cnt': 'int', 'SYN Flag Cnt': 'int', 'RST Flag Cnt': 'int', 'PSH Flag Cnt': 'int', 'ACK Flag Cnt': 'int', 'URG Flag Cnt': 'int', 'CWE Flag Count': 'int', 'ECE Flag Cnt': 'int', 'Down/Up Ratio': 'int', 'Pkt Size Avg': 'float', 'Fwd Seg Size Avg': 'float', 'Bwd Seg Size Avg': 'float', 'Fwd Byts/b Avg': 'int', 'Fwd Pkts/b Avg': 'int', 'Fwd Blk Rate Avg': 'int', 'Bwd Byts/b Avg': 'int', 'Bwd Pkts/b Avg': 'int', 'Bwd Blk Rate Avg': 'int', 'Subflow Fwd Pkts': 'int', 'Subflow Fwd Byts': 'int', 'Subflow Bwd Pkts': 'int', 'Subflow Bwd Byts': 'int', 'Init Fwd Win Byts': 'int', 'Init Bwd Win Byts': 'int', 'Fwd Act Data Pkts': 'int', 'Fwd Seg Size Min': 'int', 'Active Mean': 'float', 'Active Std': 'float', 'Active Max': 'int', 'Active Min': 'int', 'Idle Mean': 'float', 'Idle Std': 'float', 'Idle Max': 'int', 'Idle Min': 'int', 'Label': 'object'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "647bbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.astype(chage_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4ab49bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2963969 entries, 0 to 2963968\n",
      "Data columns (total 80 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Dst Port           int64  \n",
      " 1   Protocol           int64  \n",
      " 2   Timestamp          object \n",
      " 3   Flow Duration      int64  \n",
      " 4   Tot Fwd Pkts       int64  \n",
      " 5   Tot Bwd Pkts       int64  \n",
      " 6   TotLen Fwd Pkts    int64  \n",
      " 7   TotLen Bwd Pkts    int64  \n",
      " 8   Fwd Pkt Len Max    int64  \n",
      " 9   Fwd Pkt Len Min    int64  \n",
      " 10  Fwd Pkt Len Mean   float64\n",
      " 11  Fwd Pkt Len Std    float64\n",
      " 12  Bwd Pkt Len Max    int64  \n",
      " 13  Bwd Pkt Len Min    int64  \n",
      " 14  Bwd Pkt Len Mean   float64\n",
      " 15  Bwd Pkt Len Std    float64\n",
      " 16  Flow Byts/s        float64\n",
      " 17  Flow Pkts/s        float64\n",
      " 18  Flow IAT Mean      float64\n",
      " 19  Flow IAT Std       float64\n",
      " 20  Flow IAT Max       int64  \n",
      " 21  Flow IAT Min       int64  \n",
      " 22  Fwd IAT Tot        int64  \n",
      " 23  Fwd IAT Mean       float64\n",
      " 24  Fwd IAT Std        float64\n",
      " 25  Fwd IAT Max        int64  \n",
      " 26  Fwd IAT Min        int64  \n",
      " 27  Bwd IAT Tot        int64  \n",
      " 28  Bwd IAT Mean       float64\n",
      " 29  Bwd IAT Std        float64\n",
      " 30  Bwd IAT Max        int64  \n",
      " 31  Bwd IAT Min        int64  \n",
      " 32  Fwd PSH Flags      int64  \n",
      " 33  Bwd PSH Flags      int64  \n",
      " 34  Fwd URG Flags      int64  \n",
      " 35  Bwd URG Flags      int64  \n",
      " 36  Fwd Header Len     int64  \n",
      " 37  Bwd Header Len     int64  \n",
      " 38  Fwd Pkts/s         float64\n",
      " 39  Bwd Pkts/s         float64\n",
      " 40  Pkt Len Min        int64  \n",
      " 41  Pkt Len Max        int64  \n",
      " 42  Pkt Len Mean       float64\n",
      " 43  Pkt Len Std        float64\n",
      " 44  Pkt Len Var        float64\n",
      " 45  FIN Flag Cnt       int64  \n",
      " 46  SYN Flag Cnt       int64  \n",
      " 47  RST Flag Cnt       int64  \n",
      " 48  PSH Flag Cnt       int64  \n",
      " 49  ACK Flag Cnt       int64  \n",
      " 50  URG Flag Cnt       int64  \n",
      " 51  CWE Flag Count     int64  \n",
      " 52  ECE Flag Cnt       int64  \n",
      " 53  Down/Up Ratio      int64  \n",
      " 54  Pkt Size Avg       float64\n",
      " 55  Fwd Seg Size Avg   float64\n",
      " 56  Bwd Seg Size Avg   float64\n",
      " 57  Fwd Byts/b Avg     int64  \n",
      " 58  Fwd Pkts/b Avg     int64  \n",
      " 59  Fwd Blk Rate Avg   int64  \n",
      " 60  Bwd Byts/b Avg     int64  \n",
      " 61  Bwd Pkts/b Avg     int64  \n",
      " 62  Bwd Blk Rate Avg   int64  \n",
      " 63  Subflow Fwd Pkts   int64  \n",
      " 64  Subflow Fwd Byts   int64  \n",
      " 65  Subflow Bwd Pkts   int64  \n",
      " 66  Subflow Bwd Byts   int64  \n",
      " 67  Init Fwd Win Byts  int64  \n",
      " 68  Init Bwd Win Byts  int64  \n",
      " 69  Fwd Act Data Pkts  int64  \n",
      " 70  Fwd Seg Size Min   int64  \n",
      " 71  Active Mean        float64\n",
      " 72  Active Std         float64\n",
      " 73  Active Max         int64  \n",
      " 74  Active Min         int64  \n",
      " 75  Idle Mean          float64\n",
      " 76  Idle Std           float64\n",
      " 77  Idle Max           int64  \n",
      " 78  Idle Min           int64  \n",
      " 79  Label              object \n",
      "dtypes: float64(24), int64(54), object(2)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info() #顯示詳細資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2206fdd",
   "metadata": {},
   "source": [
    "## **數據前處理**\n",
    "數據預處理在數據科學過程中起著重要作用，因為數據可能不完全乾淨，並且可能包含缺失值或空值。\n",
    "在這一步中，我們正在進行一些預處理步驟，如果我們的數據中有任何空值或缺失值，這將有助於我們。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec4230ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0, 5846,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#采用isna()函數以檢測 DataFrame 中的缺失值。\n",
    "df.isna().sum().to_numpy()\n",
    "#我們需要從我們的數據中刪除\"此列\"(不是刪除此特徵)，以便我們的數據可以被清理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "476990ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2958123 entries, 0 to 2963968\n",
      "Data columns (total 80 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Dst Port           int64  \n",
      " 1   Protocol           int64  \n",
      " 2   Timestamp          object \n",
      " 3   Flow Duration      int64  \n",
      " 4   Tot Fwd Pkts       int64  \n",
      " 5   Tot Bwd Pkts       int64  \n",
      " 6   TotLen Fwd Pkts    int64  \n",
      " 7   TotLen Bwd Pkts    int64  \n",
      " 8   Fwd Pkt Len Max    int64  \n",
      " 9   Fwd Pkt Len Min    int64  \n",
      " 10  Fwd Pkt Len Mean   float64\n",
      " 11  Fwd Pkt Len Std    float64\n",
      " 12  Bwd Pkt Len Max    int64  \n",
      " 13  Bwd Pkt Len Min    int64  \n",
      " 14  Bwd Pkt Len Mean   float64\n",
      " 15  Bwd Pkt Len Std    float64\n",
      " 16  Flow Byts/s        float64\n",
      " 17  Flow Pkts/s        float64\n",
      " 18  Flow IAT Mean      float64\n",
      " 19  Flow IAT Std       float64\n",
      " 20  Flow IAT Max       int64  \n",
      " 21  Flow IAT Min       int64  \n",
      " 22  Fwd IAT Tot        int64  \n",
      " 23  Fwd IAT Mean       float64\n",
      " 24  Fwd IAT Std        float64\n",
      " 25  Fwd IAT Max        int64  \n",
      " 26  Fwd IAT Min        int64  \n",
      " 27  Bwd IAT Tot        int64  \n",
      " 28  Bwd IAT Mean       float64\n",
      " 29  Bwd IAT Std        float64\n",
      " 30  Bwd IAT Max        int64  \n",
      " 31  Bwd IAT Min        int64  \n",
      " 32  Fwd PSH Flags      int64  \n",
      " 33  Bwd PSH Flags      int64  \n",
      " 34  Fwd URG Flags      int64  \n",
      " 35  Bwd URG Flags      int64  \n",
      " 36  Fwd Header Len     int64  \n",
      " 37  Bwd Header Len     int64  \n",
      " 38  Fwd Pkts/s         float64\n",
      " 39  Bwd Pkts/s         float64\n",
      " 40  Pkt Len Min        int64  \n",
      " 41  Pkt Len Max        int64  \n",
      " 42  Pkt Len Mean       float64\n",
      " 43  Pkt Len Std        float64\n",
      " 44  Pkt Len Var        float64\n",
      " 45  FIN Flag Cnt       int64  \n",
      " 46  SYN Flag Cnt       int64  \n",
      " 47  RST Flag Cnt       int64  \n",
      " 48  PSH Flag Cnt       int64  \n",
      " 49  ACK Flag Cnt       int64  \n",
      " 50  URG Flag Cnt       int64  \n",
      " 51  CWE Flag Count     int64  \n",
      " 52  ECE Flag Cnt       int64  \n",
      " 53  Down/Up Ratio      int64  \n",
      " 54  Pkt Size Avg       float64\n",
      " 55  Fwd Seg Size Avg   float64\n",
      " 56  Bwd Seg Size Avg   float64\n",
      " 57  Fwd Byts/b Avg     int64  \n",
      " 58  Fwd Pkts/b Avg     int64  \n",
      " 59  Fwd Blk Rate Avg   int64  \n",
      " 60  Bwd Byts/b Avg     int64  \n",
      " 61  Bwd Pkts/b Avg     int64  \n",
      " 62  Bwd Blk Rate Avg   int64  \n",
      " 63  Subflow Fwd Pkts   int64  \n",
      " 64  Subflow Fwd Byts   int64  \n",
      " 65  Subflow Bwd Pkts   int64  \n",
      " 66  Subflow Bwd Byts   int64  \n",
      " 67  Init Fwd Win Byts  int64  \n",
      " 68  Init Bwd Win Byts  int64  \n",
      " 69  Fwd Act Data Pkts  int64  \n",
      " 70  Fwd Seg Size Min   int64  \n",
      " 71  Active Mean        float64\n",
      " 72  Active Std         float64\n",
      " 73  Active Max         int64  \n",
      " 74  Active Min         int64  \n",
      " 75  Idle Mean          float64\n",
      " 76  Idle Std           float64\n",
      " 77  Idle Max           int64  \n",
      " 78  Idle Min           int64  \n",
      " 79  Label              object \n",
      "dtypes: float64(24), int64(54), object(2)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "source": [
    "# 刪除空列或缺失列\n",
    "df=df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87be3c73",
   "metadata": {},
   "source": [
    "## **label Encoding**\n",
    "數據中的Label Features包含 3 個Labels，分別是 Benign、BruteForceFTP 和 BruteForceSSH\n",
    "所有這些都是字符串格式。\n",
    "對於我們的神經網絡，我們需要將它們轉換為數字，以便我們的 NN 可以理解它們的表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f36bf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4, 5, 6, 2, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #labelencoder是將文字mapping到一個數字，類似的有one hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label']= label_encoder.fit_transform(df['Label'])\n",
    "df['Label'].unique()\n",
    "# for row in df:\n",
    "#     if row['Label']=='Benign':\n",
    "#         row['Label'] = 0\n",
    "#     else: row['Label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7883543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1709999\n",
       "2     576191\n",
       "1     286191\n",
       "6     193354\n",
       "4     139890\n",
       "3      41508\n",
       "5      10990\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "448351e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 為CNN塑造數據，必須遵循以下步驟\n",
    "#1.Seperate the data of each of the labels (分離每個標籤的數據)\n",
    "#2.Create a numerical matrix representation of labels(創建標籤的數字矩陣表示)\n",
    "#3.Apply resampling on data so that can make the distribution equal for all labels(對數據應用重採樣，以使所有標籤的分佈均等)\n",
    "#4.Create X (predictor) and Y (target) variables(創建 X（預測）和 Y（目標）變量)\n",
    "#5.Split the data into train and test sets(將數據拆分為訓練集和測試集)\n",
    "#6.Make data multi-dimensional for CNN(為 CNN 製作多維數據)\n",
    "#7.Apply CNN on data(將 CNN 應用於數據)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29c777a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 3 seperate datasets for 3 feature labels\n",
    "\n",
    "data_0 = df[df['Label'] == 0]\n",
    "data_1 = df[df['Label'] == 1]\n",
    "data_2 = df[df['Label'] == 2]\n",
    "data_3 = df[df['Label'] == 3]\n",
    "data_4 = df[df['Label'] == 4]\n",
    "data_5 = df[df['Label'] == 5]\n",
    "data_6 = df[df['Label'] == 6]\n",
    "# data_7 = df[df['Label'] == 7]\n",
    "# data_8 = df[df['Label'] == 8]\n",
    "# data_9 = df[df['Label'] == 9]\n",
    "# data_10 = df[df['Label'] == 10]\n",
    "\n",
    "# make benign feature\n",
    "y_0 = np.zeros(data_0.shape[0])\n",
    "y_benign = pd.DataFrame(y_0)\n",
    "\n",
    "# make botnet feature\n",
    "malicious = pd.concat([data_1, data_2, data_3, data_4, data_5, data_6])\n",
    "y_1 = np.ones(malicious.shape[0])\n",
    "y_malicious = pd.DataFrame(y_1)\n",
    "\n",
    "# # make ddos_HOIC feature\n",
    "# y_2 = np.full(data_2.shape[0],2)\n",
    "# y_ddos_HOIC = pd.DataFrame(y_2)\n",
    "\n",
    "# # make ddos_LOIC_http feature\n",
    "# y_3 = np.full(data_3.shape[0], 3)\n",
    "# y_ddos_LOIC_http = pd.DataFrame(y_3)\n",
    "\n",
    "# # make dos_goldeneyes feature\n",
    "# y_4 = np.full(data_4.shape[0], 4)\n",
    "# y_dos_goldeneyes = pd.DataFrame(y_4)\n",
    "\n",
    "# # make dos_hlk feature\n",
    "# y_5 = np.full(data_5.shape[0], 5)\n",
    "# y_dos_hulk = pd.DataFrame(y_5)\n",
    "\n",
    "# # make dos_slow_http feature\n",
    "# y_6 = np.full(data_6.shape[0], 6)\n",
    "# y_dos_slow_http = pd.DataFrame(y_6)\n",
    "\n",
    "# # make dos_slowloris feature\n",
    "# y_7 = np.full(data_7.shape[0], 7)\n",
    "# y_dos_slowloris = pd.DataFrame(y_7)\n",
    "\n",
    "# # make brute_FTP feature\n",
    "# y_8 = np.full(data_8.shape[0], 8)\n",
    "# y_brute_FTP = pd.DataFrame(y_8)\n",
    "\n",
    "# # make Infileration feature\n",
    "# y_9 = np.full(data_9.shape[0], 9)\n",
    "# y_Infileration = pd.DataFrame(y_9)\n",
    "\n",
    "# # make brute_SSH feature\n",
    "# y_10 = np.full(data_10.shape[0], 10)\n",
    "# y_brute_SSH = pd.DataFrame(y_10)\n",
    "\n",
    "# merging the original dataframe\n",
    "X = pd.concat([data_0,malicious])\n",
    "y = pd.concat([y_benign, y_malicious])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a09faddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2958123, 80)\n",
      "(2958123, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f9dcebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b9404fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = [\"Timestamp\", \"Protocol\",\"PSH Flag Cnt\",\"Init Fwd Win Byts\",\"Flow Byts/s\",\"Flow Pkts/s\", \"Label\"], axis=1)\n",
    "X_test = X_test.drop(columns = [\"Timestamp\", \"Protocol\",\"PSH Flag Cnt\",\"Init Fwd Win Byts\",\"Flow Byts/s\",\"Flow Pkts/s\", \"Label\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "057241fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "629efe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1981942, 73)\n",
      "(976181, 73)\n",
      "(1981942, 2)\n",
      "(976181, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "# y_train = y_train.to_numpy()\n",
    "# y_test = y_test.to_numpy()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93e9a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1981942, 73), (976181, 73))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape the data for CNN\n",
    "X_train = X_train.reshape(len(X_train), X_train.shape[1])\n",
    "X_test = X_test.reshape(len(X_test), X_test.shape[1])\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f841f5",
   "metadata": {},
   "source": [
    "## **CNN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6da0a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the deep learning function\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=6, activation='relu', \n",
    "                    padding='same', input_shape=(73, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # adding a pooling layer\n",
    "    model.add(MaxPooling1D(pool_size=(3), strides=2, padding='same'))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=6, activation='relu', \n",
    "                    padding='same', input_shape=(73, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=(3), strides=2, padding='same'))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=6, activation='relu', \n",
    "                    padding='same', input_shape=(73, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=(3), strides=2, padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f589dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 73, 64)            448       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 73, 64)           256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 37, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 37, 64)            24640     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 37, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 19, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 19, 64)            24640     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 19, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 10, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 640)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                41024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,594\n",
      "Trainable params: 92,210\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 11:18:04.150625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-11 11:18:04.200975: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ne6101157/anaconda3/env/trackformer/lib\n",
      "2022-11-11 11:18:04.200994: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-11 11:18:04.202527: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e0567c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = CSVLogger('logs.csv', append=True)\n",
    "# his = model.fit(X_train, y_train, epochs=10, batch_size=128, \n",
    "# validation_data=(X_test, y_test), callbacks=[logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c2cf564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the model performance on test data\n",
    "# scores = model.evaluate(X_test, y_test)\n",
    "# print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31a16898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check history of model\n",
    "# history = his.history\n",
    "# history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f6fad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = range(1, len(history['loss']) + 1)\n",
    "# acc = history['accuracy']\n",
    "# loss = history['loss']\n",
    "# val_acc = history['val_accuracy']\n",
    "# val_loss = history['val_loss']\n",
    "\n",
    "# # visualize training and val accuracy\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.title('Training and Validation Accuracy (CNN)')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.plot(epochs, acc, label='accuracy')\n",
    "# plt.plot(epochs, val_acc, label='val_acc')\n",
    "# plt.legend()\n",
    "\n",
    "# # visualize train and val loss\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.title('Training and Validation Loss(CNN)')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.plot(epochs, loss, label='loss', color='g')\n",
    "# plt.plot(epochs, val_loss, label='val_loss', color='r')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "718b3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('cic-ids.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa38825",
   "metadata": {},
   "source": [
    "## **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e35c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "# define the datasets to evaluate each iteration\n",
    "evalset = [(X_train, y_train), (X_test,y_test)]\n",
    "\n",
    "# 建立 XGBClassifier 模型\n",
    "xgboostModel = XGBClassifier(n_estimators=100, learning_rate= 0.3)\n",
    "# 使用訓練資料訓練模型\n",
    "xgboostModel.fit(X_train, y_train, eval_metric='logloss', eval_set=evalset)\n",
    "\n",
    "# evaluate performance\n",
    "yhat = xgboostModel.predict(X_test)\n",
    "# # 使用訓練資料預測分類\n",
    "# predicted = xgboostModel.predict(X_train)\n",
    "\n",
    "results = xgboostModel.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c651a6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集:  0.9996947438421507\n",
      "測試集:  0.999602532727025\n"
     ]
    }
   ],
   "source": [
    "# 預測成功的比例\n",
    "print('訓練集: ',xgboostModel.score(X_train,y_train))\n",
    "print('測試集: ',xgboostModel.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eafd2f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboostModel.save_model('cic_xgboost.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb95441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7d72da7d18bf6dd826c122707effdbffea5f684a5e28bd6ffebff0ae53dc66d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
